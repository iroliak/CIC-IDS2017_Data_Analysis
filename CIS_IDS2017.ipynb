{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUgxzwisi81a4PLDgJXBYe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iroliak/CIC-IDS2017_Data_Analysis/blob/main/CIS_IDS2017.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ανάλυση του CIS-IDS2017 Dataset\n",
        "---"
      ],
      "metadata": {
        "id": "1FFia7MZlhWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Σύντομη Περιγραφή"
      ],
      "metadata": {
        "id": "KF18QMzloZ51"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Το CIC-IDS2017 (Canadian Institute for Cybersecurity - Intrusion Detection System 2017) είναι ένα σύνολο δεδομένων που δημιουργήθηκε για την αξιολόγηση των συστημάτων ανίχνευσης εισβολών (IDS). Ο σκοπός του είναι να παρέχει ένα περιβάλλον για την ανάλυση των συμπεριφορών δικτύου και την ανάπτυξη αλγορίθμων μηχανικής μάθησης που μπορούν να ανιχνεύσουν κακόβουλες δραστηριότητες σε δίκτυα.\n",
        "\n",
        "**Περιεχόμενο:**\n",
        "Το CIC-IDS2017 περιλαμβάνει ένα ευρύ φάσμα δικτυακών επιθέσεων, όπως DDoS, Brute Force, Infiltration, και άλλες επιθέσεις, καθώς και φυσιολογική κυκλοφορία δικτύου. Τα δεδομένα περιέχουν διάφορες μετρήσεις και χαρακτηριστικά δικτύου, όπως χρόνους ροής, μεγέθη πακέτων, και χρονικές σφραγίδες.\n",
        "\n",
        "**Εφαρμογές:**\n",
        "Το dataset χρησιμοποιείται ευρέως στην έρευνα για την ανάπτυξη και αξιολόγηση μοντέλων μηχανικής μάθησης που μπορούν να ανιχνεύσουν και να κατατάξουν κακόβουλες δραστηριότητες σε δίκτυα. Είναι ιδιαίτερα χρήσιμο για την εκπαίδευση, τον έλεγχο και την αξιολόγηση συστημάτων ανίχνευσης εισβολών.\n",
        "\n",
        "**Χαρακτηριστικά:**\n",
        "Το CIC-IDS2017 είναι μια συλλογή δεδομένων πραγματικού κόσμου, που περιλαμβάνει περίπου 80 χαρακτηριστικά ανά ροή δικτύου, όπως αριθμός πακέτων, μέσο μέγεθος πακέτου, διάρκεια ροής, κ.λπ. Τα δεδομένα είναι κατηγοριοποιημένα σε επιθέσεις και φυσιολογικές ροές."
      ],
      "metadata": {
        "id": "40Hx3BVWo3IH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Πρακτική Εφαρμογή"
      ],
      "metadata": {
        "id": "9uDUXfEeow8P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Εισαγωγή και φόρτωση δεδομένων"
      ],
      "metadata": {
        "id": "oD035HmAmQq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Σύνδεση στο Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ορισμός του μονοπατιού του φακέλου που περιέχει τα CSV αρχεία στο Google Drive\n",
        "folder_path = '/content/drive/My Drive/MachineLearningCVE/'\n",
        "\n",
        "# Λίστα με όλα τα CSV αρχεία στον φάκελο\n",
        "csv_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
        "\n",
        "# Ανάγνωση και συγχώνευση όλων των CSV αρχείων σε ένα DataFrame\n",
        "df_list = [pd.read_csv(file) for file in csv_files]\n",
        "df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "# Προβολή των πρώτων γραμμών του DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpokQG0WmT77",
        "outputId": "231e160a-d65a-4ab8-bc8e-d7edc1d9053e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "    Destination Port   Flow Duration   Total Fwd Packets  \\\n",
            "0              54865               3                   2   \n",
            "1              55054             109                   1   \n",
            "2              55055              52                   1   \n",
            "3              46236              34                   1   \n",
            "4              54863               3                   2   \n",
            "\n",
            "    Total Backward Packets  Total Length of Fwd Packets  \\\n",
            "0                        0                           12   \n",
            "1                        1                            6   \n",
            "2                        1                            6   \n",
            "3                        1                            6   \n",
            "4                        0                           12   \n",
            "\n",
            "    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
            "0                             0                       6   \n",
            "1                             6                       6   \n",
            "2                             6                       6   \n",
            "3                             6                       6   \n",
            "4                             0                       6   \n",
            "\n",
            "    Fwd Packet Length Min   Fwd Packet Length Mean   Fwd Packet Length Std  \\\n",
            "0                       6                      6.0                     0.0   \n",
            "1                       6                      6.0                     0.0   \n",
            "2                       6                      6.0                     0.0   \n",
            "3                       6                      6.0                     0.0   \n",
            "4                       6                      6.0                     0.0   \n",
            "\n",
            "   ...   min_seg_size_forward  Active Mean   Active Std   Active Max  \\\n",
            "0  ...                     20          0.0          0.0            0   \n",
            "1  ...                     20          0.0          0.0            0   \n",
            "2  ...                     20          0.0          0.0            0   \n",
            "3  ...                     20          0.0          0.0            0   \n",
            "4  ...                     20          0.0          0.0            0   \n",
            "\n",
            "    Active Min  Idle Mean   Idle Std   Idle Max   Idle Min   Label  \n",
            "0            0        0.0        0.0          0          0  BENIGN  \n",
            "1            0        0.0        0.0          0          0  BENIGN  \n",
            "2            0        0.0        0.0          0          0  BENIGN  \n",
            "3            0        0.0        0.0          0          0  BENIGN  \n",
            "4            0        0.0        0.0          0          0  BENIGN  \n",
            "\n",
            "[5 rows x 79 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Προεπεξεργασία - Διατήρηση Χρήσιμων Στηλών"
      ],
      "metadata": {
        "id": "98skkP7fmb71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Επιλογή των χαρακτηριστικών (X) και του στόχου (y)\n",
        "X = df.drop(' Label', axis=1)  # Όλες οι στήλες εκτός από το ' Label'\n",
        "y = df[' Label']  # Στήλη στόχου\n",
        "\n",
        "# Εξέταση των πρώτων γραμμών του X και του y για να επιβεβαιώσουμε ότι ορίστηκαν σωστά\n",
        "print(X.head())\n",
        "print(y.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMbzkED-mc3z",
        "outputId": "0a30bb7d-8069-4108-f327-2f034e6bc9f4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Destination Port   Flow Duration   Total Fwd Packets  \\\n",
            "0              54865               3                   2   \n",
            "1              55054             109                   1   \n",
            "2              55055              52                   1   \n",
            "3              46236              34                   1   \n",
            "4              54863               3                   2   \n",
            "\n",
            "    Total Backward Packets  Total Length of Fwd Packets  \\\n",
            "0                        0                           12   \n",
            "1                        1                            6   \n",
            "2                        1                            6   \n",
            "3                        1                            6   \n",
            "4                        0                           12   \n",
            "\n",
            "    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
            "0                             0                       6   \n",
            "1                             6                       6   \n",
            "2                             6                       6   \n",
            "3                             6                       6   \n",
            "4                             0                       6   \n",
            "\n",
            "    Fwd Packet Length Min   Fwd Packet Length Mean   Fwd Packet Length Std  \\\n",
            "0                       6                      6.0                     0.0   \n",
            "1                       6                      6.0                     0.0   \n",
            "2                       6                      6.0                     0.0   \n",
            "3                       6                      6.0                     0.0   \n",
            "4                       6                      6.0                     0.0   \n",
            "\n",
            "   ...   act_data_pkt_fwd   min_seg_size_forward  Active Mean   Active Std  \\\n",
            "0  ...                  1                     20          0.0          0.0   \n",
            "1  ...                  0                     20          0.0          0.0   \n",
            "2  ...                  0                     20          0.0          0.0   \n",
            "3  ...                  0                     20          0.0          0.0   \n",
            "4  ...                  1                     20          0.0          0.0   \n",
            "\n",
            "    Active Max   Active Min  Idle Mean   Idle Std   Idle Max   Idle Min  \n",
            "0            0            0        0.0        0.0          0          0  \n",
            "1            0            0        0.0        0.0          0          0  \n",
            "2            0            0        0.0        0.0          0          0  \n",
            "3            0            0        0.0        0.0          0          0  \n",
            "4            0            0        0.0        0.0          0          0  \n",
            "\n",
            "[5 rows x 78 columns]\n",
            "0    BENIGN\n",
            "1    BENIGN\n",
            "2    BENIGN\n",
            "3    BENIGN\n",
            "4    BENIGN\n",
            "Name:  Label, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Διαμερισμός του Dataset σε Training και Test Sets"
      ],
      "metadata": {
        "id": "fjVitElrmgHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Διαχωρισμός των δεδομένων σε training και test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Εξέταση των μεγεθών των σετ για να επιβεβαιώσουμε ότι έγινε σωστά ο διαμερισμός\n",
        "print(f'Training set size: {X_train.shape[0]} samples')\n",
        "print(f'Test set size: {X_test.shape[0]} samples')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlIx66tgmimC",
        "outputId": "381b607a-7d2d-42c3-9bef-a2de5db8f477"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 2264594 samples\n",
            "Test set size: 566149 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Εντοπισμός και Αντιμετώπιση Απειρων ή Πολύ Μεγάλων Τιμών"
      ],
      "metadata": {
        "id": "8hpeyDh-8bqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Εντοπισμός απείρων τιμών\n",
        "print(\"Checking for infinite values...\")\n",
        "print(np.isinf(X_train).sum().sum())\n",
        "\n",
        "# Εντοπισμός NaN τιμών\n",
        "print(\"Checking for NaN values...\")\n",
        "print(np.isnan(X_train).sum().sum())\n",
        "\n",
        "# Αντικατάσταση απείρων τιμών με NaN\n",
        "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Αντικατάσταση ή αφαίρεση των NaN τιμών\n",
        "X_train.fillna(X_train.mean(), inplace=True)\n",
        "X_test.fillna(X_test.mean(), inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujromQm-8Y89",
        "outputId": "5f47ae46-1a60-4f3d-820b-b8c83a3d4abe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking for infinite values...\n",
            "3520\n",
            "Checking for NaN values...\n",
            "1064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Κλιμάκωση των Αριθμητικών Ιδιοτήτων (Scaling)"
      ],
      "metadata": {
        "id": "2ja44ebmmlIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Κλιμάκωση των αριθμητικών χαρακτηριστικών\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "jvQ5hXWsmpbr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Κωδικοποίηση των Κατηγορικών Στηλών (One Hot Encoding)"
      ],
      "metadata": {
        "id": "SgsuyGO6mr-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Εφαρμογή One Hot Encoding στις κατηγορικές στήλες\n",
        "encoder = OneHotEncoder()\n",
        "X_train_encoded = encoder.fit_transform(X_train_scaled)\n",
        "X_test_encoded = encoder.transform(X_test_scaled)"
      ],
      "metadata": {
        "id": "HQob5OMtmvpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Εξαγωγή Χαρακτηριστικών (Feature Extraction)"
      ],
      "metadata": {
        "id": "tPSuIDQ9myI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Εφαρμογή PCA για μείωση της διάστασης\n",
        "pca = PCA(n_components=10)  # Αριθμός συνιστωσών\n",
        "X_train_pca = pca.fit_transform(X_train_encoded.toarray())\n",
        "X_test_pca = pca.transform(X_test_encoded.toarray())"
      ],
      "metadata": {
        "id": "oS49YdrJm0x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Εφαρμογή Classifiers"
      ],
      "metadata": {
        "id": "Vgm-xoqQm3IT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Naive Bayes\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train_pca, y_train)\n",
        "nb_predictions = nb.predict(X_test_pca)\n",
        "print(\"Naive Bayes:\\n\", classification_report(y_test, nb_predictions))\n",
        "\n",
        "# Decision Tree\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train_pca, y_train)\n",
        "dt_predictions = dt.predict(X_test_pca)\n",
        "print(\"Decision Tree:\\n\", classification_report(y_test, dt_predictions))\n",
        "\n",
        "# K-Neighbors\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train_pca, y_train)\n",
        "knn_predictions = knn.predict(X_test_pca)\n",
        "print(\"K-Neighbors:\\n\", classification_report(y_test, knn_predictions))\n",
        "\n",
        "# Logistic Regression\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train_pca, y_train)\n",
        "lr_predictions = lr.predict(X_test_pca)\n",
        "print(\"Logistic Regression:\\n\", classification_report(y_test, lr_predictions))"
      ],
      "metadata": {
        "id": "57xrU_QWm5mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Σύγκριση και Ανάλυση Αποτελεσμάτων"
      ],
      "metadata": {
        "id": "qfUUHT-hm8S6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Λειτουργία για να υπολογίσουμε όλες τις μετρικές αξιολόγησης\n",
        "def evaluate_model(y_test, y_pred):\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Αποθήκευση των αποτελεσμάτων σε ένα DataFrame για ευκολότερη σύγκριση\n",
        "results = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "# Προσθήκη των αποτελεσμάτων για κάθε μοντέλο\n",
        "models = {\n",
        "    'Naive Bayes': nb_predictions,\n",
        "    'Decision Tree': dt_predictions,\n",
        "    'K-Neighbors': knn_predictions,\n",
        "    'Logistic Regression': lr_predictions\n",
        "}\n",
        "\n",
        "for model_name, y_pred in models.items():\n",
        "    accuracy, precision, recall, f1 = evaluate_model(y_test_encoded, y_pred)\n",
        "    results = results.append({\n",
        "        'Model': model_name,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1\n",
        "    }, ignore_index=True)\n",
        "\n",
        "# Εμφάνιση των αποτελεσμάτων\n",
        "print(results)\n",
        "\n",
        "# Προαιρετικά: δημιουργία διαγραμμάτων για τη σύγκριση των μοντέλων\n",
        "results.set_index('Model', inplace=True)\n",
        "results.plot(kind='bar', figsize=(10, 6), ylim=(0, 1), title=\"Comparison of Model Performance Metrics\")\n"
      ],
      "metadata": {
        "id": "pvFqJNnrZhNE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}